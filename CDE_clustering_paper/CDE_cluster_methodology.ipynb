{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSKod+MlozqBhZIB4cqtzF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. Data Preprocessing**"],"metadata":{"id":"vZia5JGfxD-A"}},{"cell_type":"markdown","source":["**Objective**: Load, clean, and structure the Common Data Elements (CDE) JSON data into a tabular format suitable for embedding and analysis.\n","\n","**Input**:  \n","- JSON file (`SearchExport.json`) with nested CDE metadata. Download URL: https://cde.nlm.nih.gov/cde/search\n","\n","**Output**:  \n","- A flattened CSV file (`NLM_CDE_JSON2DF.csv`) containing:\n","  - `tinyId`\n","  - `designation`\n","  - `definition`\n","  - `permissible values`\n","  - `stewardOrg`\n"],"metadata":{"id":"ugs_9w17cGnF"}},{"cell_type":"code","source":["import json\n","import pandas as pd\n","\n","# Load JSON data\n","with open(\"CDE_data/SearchExport.json\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n","    data = json.load(file)\n","\n","# Parse JSON into rows\n","df_list = []\n","for index, item in enumerate(data):\n","    tinyId = item[\"tinyId\"]\n","    stewardOrg = item[\"stewardOrg\"][\"name\"]\n","\n","    # Extract preferred designation\n","    designations = [d[\"designation\"] for d in item[\"designations\"] if \"Preferred Question Text\" in d[\"tags\"]]\n","    if not designations:\n","        designations = [item[\"designations\"][0][\"designation\"]]\n","\n","    # Handle missing definitions\n","    definition = item[\"definitions\"][0][\"definition\"] if item[\"definitions\"] else \"No definition available\"\n","\n","    # Format permissible values\n","    permissible_values = [\n","        f\"{v['permissibleValue']}: {v.get('valueMeaningName', v.get('valueMeaningDefinition', ''))}\"\n","        for v in item[\"valueDomain\"][\"permissibleValues\"]\n","        if \"permissibleValue\" in v\n","    ]\n","    permissible_values_str = \", \".join(permissible_values) if permissible_values else \"No permissible values\"\n","\n","    for designation in designations:\n","        df_list.append({\n","            \"index\": index,\n","            \"tinyId\": tinyId,\n","            \"designation\": designation,\n","            \"definition\": definition,\n","            \"permissible values\": permissible_values_str,\n","            \"stewardOrg\": stewardOrg\n","        })\n","\n","# Save DataFrame\n","df = pd.DataFrame(df_list)\n","df.to_csv('NLM_CDE_JSON2DF.csv', index=False)\n","print(\"Data has been successfully saved to 'NLM_CDE_JSON2DF.csv'\")\n"],"metadata":{"id":"RXp0_7D4-Xs8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Embedding Generation**"],"metadata":{"id":"X3FH0C_cEqpd"}},{"cell_type":"markdown","source":["**Objective**: Convert combined textual data into numerical vectors using OpenAI's embedding model.\n","\n","**Input**:\n","- Cleaned DataFrame (`NLM_CDE_JSON2DF.csv`)\n","\n","**Output**:\n","- A new column `embedding` in the DataFrame, storing 1D embedding vectors for each row.\n"],"metadata":{"id":"xDkcuJiVJiVl"}},{"cell_type":"code","source":["import openai\n","import pandas as pd\n","\n","# Load processed data\n","df = pd.read_csv(\"/content/drive/My Drive/CDE_CMDR_MK/NLM_CDE_JSON2DF.csv\")\n","\n","openai.api_key = \"your-openai-api-key\"\n","\n","def generate_embedding(text, model=\"text-embedding-3-small\"):\n","    if not isinstance(text, str):\n","        return None if pd.isna(text) else str(text)\n","    text = text.replace(\"\\n\", \" \")\n","    response = openai.Embedding.create(input=text, model=model)\n","    return response['data'][0]['embedding']\n","\n","df['embedding'] = df['combined'].apply(generate_embedding)\n"],"metadata":{"id":"JQPqmQlYGPT1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **3. Clustering**"],"metadata":{"id":"ob0Y_-fMxNqA"}},{"cell_type":"markdown","source":["**Objective**: Group semantically similar CDE entries using HDBSCAN based on cosine similarity of embeddings.\n","\n","**Input**:\n","- Embedding vectors (`embedding` column)\n","\n","**Output**:\n","- Cluster labels assigned to each row\n","- Evaluation metrics per cluster setting:\n","  - Silhouette Score\n","  - Dunn Index\n","  - Davies-Bouldin Index"],"metadata":{"id":"lTrKOGxuJaYI"}},{"cell_type":"code","source":["import hdbscan\n","import numpy as np\n","from sklearn.metrics import silhouette_score, davies_bouldin_score\n","from sklearn.metrics.pairwise import cosine_distances\n","from scipy.spatial.distance import cdist\n","\n","def compute_dunn_index(embeddings, labels):\n","    unique_clusters = np.unique(labels[labels != -1])\n","    if len(unique_clusters) < 2:\n","        return None\n","    centroids = np.array([embeddings[labels == c].mean(axis=0) for c in unique_clusters])\n","    inter_cluster = cdist(centroids, centroids)\n","    np.fill_diagonal(inter_cluster, np.inf)\n","    min_inter = inter_cluster.min()\n","    max_intra = max(np.max(cdist(embeddings[labels == c], embeddings[labels == c])) for c in unique_clusters)\n","    return min_inter / max_intra if max_intra > 0 else None\n","\n","# Prepare embeddings\n","embeddings = np.array(df['embedding'].tolist())\n","cos_dist = cosine_distances(embeddings)\n","\n","min_cluster_sizes = [5, 10, 15, 20, 25, 50, 75, 100, 250]\n","\n","for size in min_cluster_sizes:\n","    clusterer = hdbscan.HDBSCAN(min_cluster_size=size)\n","    labels = clusterer.fit_predict(cos_dist)\n","    valid = labels != -1\n","    if valid.sum() > 1:\n","        silhouette = silhouette_score(embeddings[valid], labels[valid])\n","        dunn = compute_dunn_index(embeddings[valid], labels[valid])\n","        db = davies_bouldin_score(embeddings[valid], labels[valid])\n","        print(f\"min_cluster_size={size} | Silhouette: {silhouette:.3f}, Dunn: {dunn:.3f}, DBI: {db:.3f}\")\n","    else:\n","        print(f\"min_cluster_size={size} | Not enough valid clusters\")\n"],"metadata":{"id":"b2gP9m4iHCAI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4. Cluster Labeling**"],"metadata":{"id":"gsTsfHMjKXU-"}},{"cell_type":"markdown","source":["**Objective**: Assign human-readable labels to each cluster by summarizing representative cluster content with a language model.\n","\n","**Input**:\n","- Grouped text for each cluster\n","- OpenAI's GPT model (`gpt-3.5-turbo`)\n","\n","**Output**:\n","- A `Cluster Name` column with a concise LLM-generated label for each cluster"],"metadata":{"id":"ZQVoIX7FHQCl"}},{"cell_type":"code","source":["def generate_cluster_prompt(cluster):\n","    combined_text = \"\\n\".join(cluster['combined'])\n","    return f\"Generate a meaningful name for this cluster based on the following combined text:\\n\\n{combined_text}\\n\\nProvide a concise cluster name.\"\n","\n","def generate_cluster_name(cluster_label, cluster_data):\n","    prompt = generate_cluster_prompt(cluster_data)\n","    response = openai.ChatCompletion.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        max_tokens=100\n","    )\n","    return response['choices'][0]['message']['content'].strip()\n","\n","df[\"Cluster Label\"] = clusterer.labels_\n","cluster_names = {label: generate_cluster_name(label, group) for label, group in df.groupby(\"Cluster Label\")}\n","df[\"Cluster Name\"] = df[\"Cluster Label\"].map(cluster_names)\n","\n","df.to_csv(\"CDE_NLM_Cluster_Names.csv\", index=False)\n"],"metadata":{"id":"Eq5AXK7jHnBp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **5. Classification Model**"],"metadata":{"id":"uD8xp2bIM923"}},{"cell_type":"markdown","source":["**Objective**: Train a classifier to predict cluster labels from embeddings, verifying the quality of unsupervised clusters.\n","\n","**Input**:\n","- Embeddings (`embedding`)\n","- Cluster Names (`Cluster Name` as labels)\n","\n","**Output**:\n","- Classification performance (Accuracy and Classification Report)\n"],"metadata":{"id":"bJxoPk8zIA5a"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","import ast\n","\n","# Load data\n","df = pd.read_csv('CDE_NLM_Complete.csv')\n","\n","X = np.array(df['embedding'].tolist())\n","y = df['Cluster Name'].values\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train classifier\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","# Evaluate\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"id":"sRbCxNZXcZ_d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gkOhIxm2caCT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Zm6wwP7vcaFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j3VQ501uIboz"},"execution_count":null,"outputs":[]}]}